{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d93d4cc6-3305-4219-9067-fab3025945ac",
   "metadata": {},
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f25114-34d7-414e-930b-163c0ac6dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmselector.data_utils import DataLoader_SimpleQA\n",
    "from llmselector.compoundai.module.debate import MultiAgentDebate\n",
    "from llmselector.compoundai.metric import Metric, compute_score\n",
    "from llmselector.compoundai.optimizer import OptimizerFullSearch, OptimizerLLMDiagnoser\n",
    "import llmselector, os\n",
    "import os\n",
    "if not os.path.exists('../cache/db_simpleqa.sqlite'): \n",
    "    !wget -P ../cache https://github.com/LLMSELECTOR/LLMSELECTOR/releases/download/0.0.1/db_simpleqa.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b3b57b2-dd4a-4425-886f-87fd9b0cae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmselector.config.config(\n",
    "    db_path=f\"../cache/db_simpleqa.sqlite\" ,\n",
    "    openai_api_key=\"YOUR_OPENAI_KEY\",\n",
    "\tanthropic_api_key=\"YOUR_ANTHROPIC_KEY\",\n",
    "\ttogether_ai_api_key=\"YOUR_TOGETHERAI_KEY\",\n",
    "\tgemini_api_key=\"YOUR_GEMINI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50409a61-078e-46b6-9fcf-0f91ee16763b",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb5e552-d563-4734-b0f2-c8009f559b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Mydataloader = DataLoader_SimpleQA()\n",
    "q_data = Mydataloader.get_query_df()\n",
    "train_df, test_df = train_test_split(q_data,test_size=0.5, random_state=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f3f8da-d0e2-4159-aed6-1f8eb580ec09",
   "metadata": {},
   "source": [
    "## 2. Specify model and eval metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "418e5af1-2e91-4eaa-8ddb-10899c7ea465",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['gpt-4o-2024-05-13','gpt-4-turbo-2024-04-09','gpt-4o-mini-2024-07-18',\n",
    "              'claude-3-5-sonnet-20240620','claude-3-haiku-20240307',\n",
    "              'gemini-1.5-pro','gemini-1.5-flash',\n",
    "              'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo','meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo','Qwen/Qwen2.5-72B-Instruct-Turbo']\n",
    "M1 = Metric('em_direct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f410760-5e66-48f1-9409-98a494029830",
   "metadata": {},
   "source": [
    "## 3. Standard systems using one fixed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47288dd5-46cc-4852-b389-ab510a18fa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|                                            | 0/2163 [00:00<?, ?it/s]\u001b[A\n",
      "Processing:   3%|█                                 | 71/2163 [00:00<00:03, 668.24it/s]\u001b[A\n",
      "Processing:   7%|██▍                              | 160/2163 [00:00<00:02, 785.07it/s]\u001b[A\n",
      "Processing:  11%|███▋                             | 239/2163 [00:00<00:02, 743.69it/s]\u001b[A\n",
      "Processing:  15%|████▊                            | 314/2163 [00:00<00:02, 626.67it/s]\u001b[A\n",
      "Processing:  18%|█████▉                           | 391/2163 [00:00<00:02, 670.29it/s]\u001b[A\n",
      "Processing:  21%|███████                          | 461/2163 [00:00<00:02, 664.05it/s]\u001b[A\n",
      "Processing:  25%|████████▏                        | 539/2163 [00:00<00:02, 695.62it/s]\u001b[A\n",
      "Processing:  29%|█████████▍                       | 619/2163 [00:00<00:02, 720.43it/s]\u001b[A\n",
      "Processing:  33%|██████████▊                      | 710/2163 [00:00<00:01, 774.79it/s]\u001b[A\n",
      "Processing:  37%|████████████▏                    | 798/2163 [00:01<00:01, 802.81it/s]\u001b[A\n",
      "Processing:  42%|█████████████▉                   | 917/2163 [00:01<00:01, 917.49it/s]\u001b[A\n",
      "Processing:  47%|██████████████▉                 | 1010/2163 [00:01<00:01, 681.68it/s]\u001b[A\n",
      "Processing:  51%|████████████████▏               | 1098/2163 [00:01<00:01, 728.99it/s]\u001b[A\n",
      "Processing:  55%|█████████████████▌              | 1188/2163 [00:01<00:01, 771.00it/s]\u001b[A\n",
      "Processing:  59%|██████████████████▊             | 1272/2163 [00:01<00:01, 769.79it/s]\u001b[A\n",
      "Processing:  63%|████████████████████            | 1354/2163 [00:01<00:01, 667.37it/s]\u001b[A\n",
      "Processing:  66%|█████████████████████           | 1426/2163 [00:01<00:01, 656.29it/s]\u001b[A\n",
      "Processing:  70%|██████████████████████▍         | 1513/2163 [00:02<00:00, 706.70it/s]\u001b[A\n",
      "Processing:  74%|███████████████████████▋        | 1603/2163 [00:02<00:00, 755.69it/s]\u001b[A\n",
      "Processing:  78%|████████████████████████▉       | 1682/2163 [00:02<00:00, 733.21it/s]\u001b[A\n",
      "Processing:  81%|██████████████████████████      | 1760/2163 [00:02<00:00, 745.81it/s]\u001b[A\n",
      "Processing:  85%|███████████████████████████▏    | 1837/2163 [00:02<00:00, 745.23it/s]\u001b[A\n",
      "Processing:  89%|████████████████████████████▍   | 1921/2163 [00:02<00:00, 768.95it/s]\u001b[A\n",
      "Processing:  93%|█████████████████████████████▋  | 2005/2163 [00:02<00:00, 785.24it/s]\u001b[A\n",
      "Processing: 100%|████████████████████████████████| 2163/2163 [00:02<00:00, 744.05it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gpt-4o-2024-05-13', 'gpt-4o-2024-05-13', 'gpt-4o-2024-05-13', 'gpt-4o-2024-05-13', 'gpt-4o-2024-05-13', 'gpt-4o-2024-05-13', 'gpt-4o-2024-05-13')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|                                            | 0/2163 [00:00<?, ?it/s]\u001b[A\n",
      "Processing:   4%|█▍                                | 91/2163 [00:00<00:02, 889.81it/s]\u001b[A\n",
      "Processing:  10%|███▏                            | 214/2163 [00:00<00:01, 1087.85it/s]\u001b[A\n",
      "Processing:  15%|████▊                           | 326/2163 [00:00<00:01, 1099.83it/s]\u001b[A\n",
      "Processing:  20%|██████▍                         | 437/2163 [00:00<00:01, 1004.31it/s]\u001b[A\n",
      "Processing:  25%|████████▏                        | 539/2163 [00:00<00:01, 918.36it/s]\u001b[A\n",
      "Processing:  29%|█████████▋                       | 633/2163 [00:00<00:01, 844.72it/s]\u001b[A\n",
      "Processing:  33%|██████████▉                      | 720/2163 [00:00<00:01, 845.44it/s]\u001b[A\n",
      "Processing:  37%|████████████▎                    | 806/2163 [00:00<00:01, 849.40it/s]\u001b[A\n",
      "Processing:  41%|█████████████▌                   | 892/2163 [00:01<00:01, 831.97it/s]\u001b[A\n",
      "Processing:  45%|██████████████▉                  | 976/2163 [00:01<00:01, 825.97it/s]\u001b[A\n",
      "Processing:  49%|███████████████▋                | 1059/2163 [00:01<00:01, 686.17it/s]\u001b[A\n",
      "Processing:  52%|████████████████▋               | 1132/2163 [00:01<00:01, 607.06it/s]\u001b[A\n",
      "Processing:  56%|█████████████████▊              | 1203/2163 [00:01<00:01, 629.93it/s]\u001b[A\n",
      "Processing:  60%|███████████████████             | 1287/2163 [00:01<00:01, 681.32it/s]\u001b[A\n",
      "Processing:  63%|████████████████████            | 1359/2163 [00:01<00:01, 597.44it/s]\u001b[A\n",
      "Processing:  67%|█████████████████████▌          | 1456/2163 [00:01<00:01, 686.62it/s]\u001b[A\n",
      "Processing:  72%|███████████████████████▏        | 1564/2163 [00:01<00:00, 786.68it/s]\u001b[A\n",
      "Processing:  78%|█████████████████████████       | 1690/2163 [00:02<00:00, 914.11it/s]\u001b[A\n",
      "Processing:  84%|██████████████████████████▊     | 1814/2163 [00:02<00:00, 999.27it/s]\u001b[A\n",
      "Processing:  90%|███████████████████████████▊   | 1943/2163 [00:02<00:00, 1078.81it/s]\u001b[A\n",
      "Processing: 100%|████████████████████████████████| 2163/2163 [00:02<00:00, 868.43it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gpt-4-turbo-2024-04-09', 'gpt-4-turbo-2024-04-09', 'gpt-4-turbo-2024-04-09', 'gpt-4-turbo-2024-04-09', 'gpt-4-turbo-2024-04-09', 'gpt-4-turbo-2024-04-09', 'gpt-4-turbo-2024-04-09')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|                                            | 0/2163 [00:00<?, ?it/s]\u001b[A\n",
      "Processing:   4%|█▏                                | 76/2163 [00:00<00:02, 757.15it/s]\u001b[A\n",
      "Processing:   7%|██▎                              | 152/2163 [00:00<00:02, 758.00it/s]\u001b[A\n",
      "Processing:  11%|███▋                             | 240/2163 [00:00<00:02, 798.96it/s]\u001b[A\n",
      "Processing:  15%|████▉                            | 320/2163 [00:00<00:02, 721.64it/s]\u001b[A\n",
      "Processing:  18%|██████                           | 394/2163 [00:00<00:02, 603.95it/s]\u001b[A\n",
      "Processing:  21%|██████▉                          | 458/2163 [00:00<00:04, 341.17it/s]\u001b[A\n",
      "Processing:  23%|███████▋                         | 506/2163 [00:01<00:04, 335.96it/s]\u001b[A\n",
      "Processing:  25%|████████▍                        | 549/2163 [00:01<00:04, 339.93it/s]\u001b[A\n",
      "Processing:  28%|█████████▏                       | 600/2163 [00:01<00:04, 374.18it/s]\u001b[A\n",
      "Processing:  31%|██████████▎                      | 672/2163 [00:01<00:03, 453.43it/s]\u001b[A\n",
      "Processing:  35%|███████████▍                     | 750/2163 [00:01<00:02, 529.37it/s]\u001b[A\n",
      "Processing:  38%|████████████▋                    | 829/2163 [00:01<00:02, 596.73it/s]\u001b[A\n",
      "Processing:  43%|██████████████                   | 924/2163 [00:01<00:01, 691.90it/s]\u001b[A\n",
      "Processing:  47%|███████████████                 | 1018/2163 [00:01<00:01, 760.29it/s]\u001b[A\n",
      "Processing:  51%|████████████████▎               | 1099/2163 [00:01<00:01, 767.28it/s]\u001b[A\n",
      "Processing:  55%|█████████████████▋              | 1197/2163 [00:02<00:01, 827.60it/s]\u001b[A\n",
      "Processing:  60%|███████████████████▏            | 1301/2163 [00:02<00:00, 881.18it/s]\u001b[A\n",
      "Processing:  65%|████████████████████▋           | 1402/2163 [00:02<00:00, 918.12it/s]\u001b[A\n",
      "Processing:  69%|██████████████████████▏         | 1501/2163 [00:02<00:00, 937.25it/s]\u001b[A\n",
      "Processing:  74%|███████████████████████▋        | 1601/2163 [00:02<00:00, 940.91it/s]\u001b[A\n",
      "Processing:  79%|█████████████████████████       | 1698/2163 [00:02<00:00, 947.76it/s]\u001b[A\n",
      "Processing:  84%|██████████████████████████▋     | 1807/2163 [00:02<00:00, 986.21it/s]\u001b[A\n",
      "Processing:  89%|███████████████████████████▌   | 1921/2163 [00:02<00:00, 1024.34it/s]\u001b[A\n",
      "Processing: 100%|████████████████████████████████| 2163/2163 [00:02<00:00, 730.60it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gpt-4o-mini-2024-07-18', 'gpt-4o-mini-2024-07-18', 'gpt-4o-mini-2024-07-18', 'gpt-4o-mini-2024-07-18', 'gpt-4o-mini-2024-07-18', 'gpt-4o-mini-2024-07-18', 'gpt-4o-mini-2024-07-18')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|                                            | 0/2163 [00:00<?, ?it/s]\u001b[A\n",
      "Processing:   6%|█▉                              | 131/2163 [00:00<00:01, 1278.42it/s]\u001b[A\n",
      "Processing:  12%|███▉                            | 270/2163 [00:00<00:01, 1339.72it/s]\u001b[A\n",
      "Processing:  19%|█████▉                          | 405/2163 [00:00<00:01, 1340.42it/s]\u001b[A\n",
      "Processing:  25%|███████▉                        | 540/2163 [00:00<00:01, 1343.68it/s]\u001b[A\n",
      "Processing:  31%|█████████▉                      | 675/2163 [00:00<00:01, 1327.43it/s]\u001b[A\n",
      "Processing:  37%|███████████▉                    | 811/2163 [00:00<00:01, 1328.81it/s]\u001b[A\n",
      "Processing:  44%|██████████████                  | 950/2163 [00:00<00:00, 1346.11it/s]\u001b[A\n",
      "Processing:  50%|███████████████▌               | 1085/2163 [00:00<00:00, 1315.57it/s]\u001b[A\n",
      "Processing:  56%|█████████████████▍             | 1217/2163 [00:00<00:00, 1213.07it/s]\u001b[A\n",
      "Processing:  62%|███████████████████▏           | 1340/2163 [00:01<00:00, 1173.40it/s]\u001b[A\n",
      "Processing:  67%|████████████████████▉          | 1459/2163 [00:01<00:00, 1164.95it/s]\u001b[A\n",
      "Processing:  73%|██████████████████████▊        | 1589/2163 [00:01<00:00, 1200.64it/s]\u001b[A\n",
      "Processing:  79%|████████████████████████▌      | 1715/2163 [00:01<00:00, 1215.41it/s]\u001b[A\n",
      "Processing:  85%|██████████████████████████▍    | 1849/2163 [00:01<00:00, 1249.43it/s]\u001b[A\n",
      "Processing:  92%|████████████████████████████▍  | 1980/2163 [00:01<00:00, 1259.67it/s]\u001b[A\n",
      "Processing: 100%|███████████████████████████████| 2163/2163 [00:01<00:00, 1263.71it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20240620')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|                                            | 0/2163 [00:00<?, ?it/s]\u001b[A\n",
      "Processing:   6%|█▊                              | 125/2163 [00:00<00:01, 1247.97it/s]\u001b[A\n",
      "Processing:  12%|███▊                            | 259/2163 [00:00<00:01, 1300.96it/s]\u001b[A\n",
      "Processing:  18%|█████▊                          | 391/2163 [00:00<00:01, 1292.42it/s]\u001b[A\n",
      "Processing:  24%|███████▋                        | 521/2163 [00:00<00:01, 1293.15it/s]\u001b[A\n",
      "Processing:  30%|█████████▋                      | 651/2163 [00:00<00:01, 1172.65it/s]\u001b[A\n",
      "Processing:  36%|███████████▍                    | 770/2163 [00:00<00:01, 1108.56it/s]\u001b[A\n",
      "Processing:  41%|█████████████                   | 883/2163 [00:00<00:01, 1110.04it/s]\u001b[A\n",
      "Processing:  46%|██████████████▊                 | 998/2163 [00:00<00:01, 1119.20it/s]\u001b[A\n",
      "Processing:  51%|███████████████▉               | 1111/2163 [00:00<00:00, 1100.85it/s]\u001b[A\n",
      "Processing:  56%|█████████████████▌             | 1222/2163 [00:01<00:00, 1098.15it/s]\u001b[A\n",
      "Processing:  62%|███████████████████▎           | 1351/2163 [00:01<00:00, 1150.97it/s]\u001b[A\n",
      "Processing:  68%|█████████████████████          | 1467/2163 [00:01<00:00, 1151.18it/s]\u001b[A\n",
      "Processing:  73%|██████████████████████▋        | 1583/2163 [00:01<00:00, 1090.41it/s]\u001b[A\n",
      "Processing:  78%|████████████████████████▎      | 1693/2163 [00:01<00:00, 1080.18it/s]\u001b[A\n",
      "Processing:  84%|██████████████████████████▏    | 1824/2163 [00:01<00:00, 1145.31it/s]\u001b[A\n",
      "Processing:  91%|████████████████████████████   | 1958/2163 [00:01<00:00, 1201.94it/s]\u001b[A\n",
      "Processing: 100%|███████████████████████████████| 2163/2163 [00:01<00:00, 1175.15it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('claude-3-haiku-20240307', 'claude-3-haiku-20240307', 'claude-3-haiku-20240307', 'claude-3-haiku-20240307', 'claude-3-haiku-20240307', 'claude-3-haiku-20240307', 'claude-3-haiku-20240307')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|                                            | 0/2163 [00:00<?, ?it/s]\u001b[A\n",
      "Processing:   5%|█▌                               | 101/2163 [00:00<00:02, 994.88it/s]\u001b[A\n",
      "Processing:  10%|███                             | 210/2163 [00:00<00:01, 1049.26it/s]\u001b[A\n",
      "Processing:  15%|████▋                           | 321/2163 [00:00<00:01, 1058.54it/s]\u001b[A\n",
      "Processing:  20%|██████▍                         | 431/2163 [00:00<00:01, 1069.50it/s]\u001b[A\n",
      "Processing:  25%|████████▏                       | 551/2163 [00:00<00:01, 1107.94it/s]\u001b[A\n",
      "Processing:  31%|█████████▉                      | 671/2163 [00:00<00:01, 1132.94it/s]\u001b[A\n",
      "Processing:  37%|███████████▊                    | 796/2163 [00:00<00:01, 1169.64it/s]\u001b[A\n",
      "Processing:  43%|█████████████▊                  | 931/2163 [00:00<00:01, 1213.49it/s]\u001b[A\n",
      "Processing:  49%|███████████████▎               | 1069/2163 [00:00<00:00, 1264.39it/s]\u001b[A\n",
      "Processing:  56%|█████████████████▏             | 1201/2163 [00:01<00:00, 1279.83it/s]\u001b[A\n",
      "Processing:  62%|███████████████████▏           | 1341/2163 [00:01<00:00, 1306.21it/s]\u001b[A\n",
      "Processing:  68%|█████████████████████▏         | 1479/2163 [00:01<00:00, 1326.88it/s]\u001b[A\n",
      "Processing:  75%|███████████████████████        | 1612/2163 [00:01<00:00, 1321.59it/s]\u001b[A\n",
      "Processing:  81%|█████████████████████████      | 1750/2163 [00:01<00:00, 1338.77it/s]\u001b[A\n",
      "Processing:  87%|███████████████████████████    | 1884/2163 [00:01<00:00, 1328.75it/s]\u001b[A\n",
      "Processing:  93%|████████████████████████████▉  | 2021/2163 [00:01<00:00, 1336.85it/s]\u001b[A\n",
      "Processing: 100%|███████████████████████████████| 2163/2163 [00:01<00:00, 1254.32it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gemini-1.5-pro', 'gemini-1.5-pro', 'gemini-1.5-pro', 'gemini-1.5-pro', 'gemini-1.5-pro', 'gemini-1.5-pro', 'gemini-1.5-pro')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|                                            | 0/2163 [00:00<?, ?it/s]\u001b[A\n",
      "Processing:   5%|█▋                              | 111/2163 [00:00<00:01, 1074.10it/s]\u001b[A\n",
      "Processing:  11%|███▍                            | 231/2163 [00:00<00:01, 1133.11it/s]\u001b[A\n",
      "Processing:  17%|█████▍                          | 366/2163 [00:00<00:01, 1229.57it/s]\u001b[A\n",
      "Processing:  23%|███████▎                        | 493/2163 [00:00<00:01, 1245.11it/s]\u001b[A\n",
      "Processing:  29%|█████████▍                       | 618/2163 [00:00<00:01, 923.15it/s]\u001b[A\n",
      "Processing:  34%|███████████▏                     | 732/2163 [00:00<00:01, 980.12it/s]\u001b[A\n",
      "Processing:  40%|████████████▊                   | 867/2163 [00:00<00:01, 1084.10it/s]\u001b[A\n",
      "Processing:  46%|██████████████▋                 | 996/2163 [00:00<00:01, 1142.73it/s]\u001b[A\n",
      "Processing:  52%|████████████████               | 1123/2163 [00:01<00:00, 1175.76it/s]\u001b[A\n",
      "Processing:  58%|██████████████████             | 1256/2163 [00:01<00:00, 1219.03it/s]\u001b[A\n",
      "Processing:  64%|███████████████████▊           | 1381/2163 [00:01<00:00, 1210.78it/s]\u001b[A\n",
      "Processing:  70%|██████████████████████▎         | 1505/2163 [00:01<00:00, 975.75it/s]\u001b[A\n",
      "Processing:  75%|███████████████████████▎       | 1630/2163 [00:01<00:00, 1044.44it/s]\u001b[A\n",
      "Processing:  81%|█████████████████████████      | 1750/2163 [00:01<00:00, 1083.40it/s]\u001b[A\n",
      "Processing:  86%|██████████████████████████▋    | 1864/2163 [00:01<00:00, 1054.24it/s]\u001b[A\n",
      "Processing:  91%|████████████████████████████▎  | 1977/2163 [00:01<00:00, 1074.73it/s]\u001b[A\n",
      "Processing: 100%|███████████████████████████████| 2163/2163 [00:01<00:00, 1088.93it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gemini-1.5-flash', 'gemini-1.5-flash', 'gemini-1.5-flash', 'gemini-1.5-flash', 'gemini-1.5-flash', 'gemini-1.5-flash', 'gemini-1.5-flash')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|                                            | 0/2163 [00:00<?, ?it/s]\u001b[A\n",
      "Processing:   5%|█▋                              | 111/2163 [00:00<00:01, 1078.69it/s]\u001b[A\n",
      "Processing:  10%|███▎                            | 221/2163 [00:00<00:01, 1083.23it/s]\u001b[A\n",
      "Processing:  15%|████▉                           | 331/2163 [00:00<00:01, 1078.20it/s]\u001b[A\n",
      "Processing:  20%|██████▌                         | 441/2163 [00:00<00:01, 1079.66it/s]\u001b[A\n",
      "Processing:  26%|████████▏                       | 552/2163 [00:00<00:01, 1089.14it/s]\u001b[A\n",
      "Processing:  31%|█████████▉                      | 672/2163 [00:00<00:01, 1122.75it/s]\u001b[A\n",
      "Processing:  37%|███████████▋                    | 792/2163 [00:00<00:01, 1142.46it/s]\u001b[A\n",
      "Processing:  42%|█████████████▌                  | 918/2163 [00:00<00:01, 1178.29it/s]\u001b[A\n",
      "Processing:  48%|██████████████▊                | 1036/2163 [00:00<00:00, 1166.35it/s]\u001b[A\n",
      "Processing:  54%|████████████████▋              | 1162/2163 [00:01<00:00, 1192.03it/s]\u001b[A\n",
      "Processing:  60%|██████████████████▌            | 1295/2163 [00:01<00:00, 1231.19it/s]\u001b[A\n",
      "Processing:  66%|████████████████████▎          | 1419/2163 [00:01<00:00, 1186.17it/s]\u001b[A\n",
      "Processing:  71%|██████████████████████         | 1538/2163 [00:01<00:00, 1165.07it/s]\u001b[A\n",
      "Processing:  77%|███████████████████████▊       | 1665/2163 [00:01<00:00, 1193.98it/s]\u001b[A\n",
      "Processing:  83%|█████████████████████████▊     | 1802/2163 [00:01<00:00, 1243.13it/s]\u001b[A\n",
      "Processing:  89%|███████████████████████████▋   | 1932/2163 [00:01<00:00, 1259.03it/s]\u001b[A\n",
      "Processing: 100%|███████████████████████████████| 2163/2163 [00:01<00:00, 1180.44it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|                                            | 0/2163 [00:00<?, ?it/s]\u001b[A\n",
      "Processing:   5%|█▋                              | 111/2163 [00:00<00:01, 1087.36it/s]\u001b[A\n",
      "Processing:  11%|███▍                            | 231/2163 [00:00<00:01, 1125.50it/s]\u001b[A\n",
      "Processing:  16%|█████▏                          | 351/2163 [00:00<00:01, 1151.47it/s]\u001b[A\n",
      "Processing:  22%|███████                         | 481/2163 [00:00<00:01, 1199.04it/s]\u001b[A\n",
      "Processing:  28%|█████████                       | 611/2163 [00:00<00:01, 1232.22it/s]\u001b[A\n",
      "Processing:  34%|███████████                     | 744/2163 [00:00<00:01, 1264.39it/s]\u001b[A\n",
      "Processing:  40%|████████████▉                   | 871/2163 [00:00<00:01, 1247.67it/s]\u001b[A\n",
      "Processing:  46%|██████████████▋                 | 996/2163 [00:00<00:00, 1210.95it/s]\u001b[A\n",
      "Processing:  52%|████████████████               | 1118/2163 [00:00<00:00, 1168.73it/s]\u001b[A\n",
      "Processing:  57%|█████████████████▊             | 1241/2163 [00:01<00:00, 1181.52it/s]\u001b[A\n",
      "Processing:  63%|███████████████████▌           | 1361/2163 [00:01<00:00, 1186.11it/s]\u001b[A\n",
      "Processing:  69%|█████████████████████▎         | 1489/2163 [00:01<00:00, 1210.49it/s]\u001b[A\n",
      "Processing:  75%|███████████████████████▏       | 1618/2163 [00:01<00:00, 1231.15it/s]\u001b[A\n",
      "Processing:  81%|█████████████████████████      | 1747/2163 [00:01<00:00, 1248.24it/s]\u001b[A\n",
      "Processing:  87%|██████████████████████████▉    | 1876/2163 [00:01<00:00, 1259.09it/s]\u001b[A\n",
      "Processing:  93%|████████████████████████████▋  | 2003/2163 [00:01<00:00, 1228.34it/s]\u001b[A\n",
      "Processing: 100%|███████████████████████████████| 2163/2163 [00:01<00:00, 1215.37it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                           | 0/1 [00:00<?, ?it/s]\n",
      "Processing:   0%|                                            | 0/2163 [00:00<?, ?it/s]\u001b[A\n",
      "Processing:   6%|█▉                              | 132/2163 [00:00<00:01, 1316.21it/s]\u001b[A\n",
      "Processing:  13%|████                            | 271/2163 [00:00<00:01, 1343.69it/s]\u001b[A\n",
      "Processing:  19%|██████                          | 409/2163 [00:00<00:01, 1358.30it/s]\u001b[A\n",
      "Processing:  25%|████████                        | 545/2163 [00:00<00:01, 1354.68it/s]\u001b[A\n",
      "Processing:  31%|██████████                      | 681/2163 [00:00<00:01, 1279.13it/s]\u001b[A\n",
      "Processing:  37%|███████████▉                    | 810/2163 [00:00<00:01, 1272.37it/s]\u001b[A\n",
      "Processing:  44%|██████████████                  | 948/2163 [00:00<00:00, 1303.70it/s]\u001b[A\n",
      "Processing:  50%|███████████████▌               | 1083/2163 [00:00<00:00, 1315.12it/s]\u001b[A\n",
      "Processing:  56%|█████████████████▍             | 1215/2163 [00:00<00:00, 1303.14it/s]\u001b[A\n",
      "Processing:  62%|███████████████████▎           | 1346/2163 [00:01<00:00, 1301.13it/s]\u001b[A\n",
      "Processing:  68%|█████████████████████▏         | 1477/2163 [00:01<00:00, 1291.73it/s]\u001b[A\n",
      "Processing:  74%|███████████████████████        | 1610/2163 [00:01<00:00, 1302.99it/s]\u001b[A\n",
      "Processing:  80%|████████████████████████▉      | 1741/2163 [00:01<00:00, 1271.34it/s]\u001b[A\n",
      "Processing:  86%|██████████████████████████▊    | 1869/2163 [00:01<00:00, 1268.12it/s]\u001b[A\n",
      "Processing:  92%|████████████████████████████▌  | 1996/2163 [00:01<00:00, 1185.01it/s]\u001b[A\n",
      "Processing: 100%|███████████████████████████████| 2163/2163 [00:01<00:00, 1250.57it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Qwen/Qwen2.5-72B-Instruct-Turbo', 'Qwen/Qwen2.5-72B-Instruct-Turbo', 'Qwen/Qwen2.5-72B-Instruct-Turbo', 'Qwen/Qwen2.5-72B-Instruct-Turbo', 'Qwen/Qwen2.5-72B-Instruct-Turbo', 'Qwen/Qwen2.5-72B-Instruct-Turbo', 'Qwen/Qwen2.5-72B-Instruct-Turbo')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Agents_SameModel ={}\n",
    "for name in model_list:\n",
    "    Agents_SameModel[name] = MultiAgentDebate()\n",
    "    Opt0 = OptimizerFullSearch(model_list = [name])\n",
    "    Opt0.optimize( train_df, M1, Agents_SameModel[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc2ddc-96a2-4fba-ac8f-250d2933bec4",
   "metadata": {},
   "source": [
    "## 4. LLMSELECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052123bc-69b9-489d-961f-7ead41fa50c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 500/500 [00:10<00:00, 48.15it/s]\n",
      "100%|███████████████████████████████████████████████| 500/500 [00:12<00:00, 40.23it/s]\n",
      "100%|███████████████████████████████████████████████| 500/500 [00:09<00:00, 51.65it/s]\n",
      "100%|███████████████████████████████████████████████| 500/500 [00:09<00:00, 52.28it/s]\n",
      "100%|███████████████████████████████████████████████| 500/500 [00:09<00:00, 51.99it/s]\n",
      "100%|███████████████████████████████████████████████| 500/500 [00:11<00:00, 44.64it/s]\n",
      "100%|███████████████████████████████████████████████| 500/500 [00:08<00:00, 60.09it/s]\n",
      "100%|███████████████████████████████████████████████| 500/500 [00:09<00:00, 52.07it/s]\n",
      " 48%|██████████████████████▍                        | 239/500 [00:05<00:07, 36.23it/s]"
     ]
    }
   ],
   "source": [
    "LLMSELECTOR = MultiAgentDebate()\n",
    "Optimizer = OptimizerLLMDiagnoser(model_list = model_list)\n",
    "Optimizer.optimize( train_df.head(500), M1, LLMSELECTOR) # use only 500 samples for fast processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd25d8-6e69-40e3-a07e-9b5e95f70b53",
   "metadata": {},
   "source": [
    "## 5. Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3f488-e452-4adb-8f8d-c7f9415876a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_systems = {\"LLMSELECTOR\": LLMSELECTOR, **Agents_SameModel}\n",
    "results = compute_score(All_systems, test_df, M1)\n",
    "display(\"test accuracy\",results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a669c95-e94a-4b3e-b6a8-a25b5b80312c",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2503bfe-5c55-461d-a3e0-fb1c8dd2f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def visualize_scores(dataframe):\n",
    "    \"\"\"\n",
    "    Visualizes the Mean Scores of models in a given dataframe using Plotly.\n",
    "\n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): DataFrame containing 'Name' and 'Mean_Score' columns.\n",
    "\n",
    "    Returns:\n",
    "    - A Plotly bar chart figure.\n",
    "    \"\"\"\n",
    "    fig = px.bar(\n",
    "        dataframe,\n",
    "        x=\"Name\",\n",
    "        y=\"Mean_Score\",\n",
    "        title=\"Mean Scores of Models\",\n",
    "        labels={\"Name\": \"Model Name\", \"Mean_Score\": \"Mean Score\"},\n",
    "        text=\"Mean_Score\",\n",
    "    )\n",
    "    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(title=\"Model Name\", tickangle=45),\n",
    "        yaxis=dict(title=\"Mean Score\"),\n",
    "        margin=dict(l=40, r=40, t=40, b=100),\n",
    "        height=800,\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c73819-ece2-495e-bea9-86b6233f3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {'gpt-4o-2024-05-13': 'GPT-4o', \n",
    "            'gpt-4-turbo-2024-04-09': 'GPT-4 Turbo', \n",
    "           'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo': 'Llama 3.1 405B',\n",
    "           'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo': 'Llama 3.1 70B',            \n",
    "           'Qwen/Qwen2.5-72B-Instruct-Turbo': 'Qwen 2.5 72B',\n",
    "          }\n",
    "results['Name'] = results['Name'].replace(name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad4a04-eb96-483f-9b60-953f47c451fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scores(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac27ae-2e1d-425d-9e1e-0aecb1b579df",
   "metadata": {},
   "source": [
    "## 7. Example Deepdive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b211a4-9fd3-460c-af9b-0b761a8b561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select questions on which LLMSELECTOR is correct but other models are wrong\n",
    "model1 = 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo'\n",
    "model2 = 'claude-3-5-sonnet-20240620'\n",
    "example_df = test_df[\n",
    "(test_df['score_LLMSELECTOR']==1) &\n",
    "(test_df[f'score_{model1}']==0)\n",
    "& (test_df[f'score_{model2}']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db1143-dd9f-4bd0-b03a-6d0bb370c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "query = example_df.iloc[index]['query']\n",
    "answer = example_df.iloc[index]['true_answer']\n",
    "print(f\"question: {query}\\nanswer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa41089c-b9ca-4cc7-91cb-9eeed449bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Agents_SameModel[model1].generate(query)\n",
    "Agents_SameModel[model1].load_history()['trace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e6a15-5320-42c0-9c96-07201466437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Agents_SameModel[model2].generate(query)\n",
    "Agents_SameModel[model2].load_history()['trace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ababe3-5f9e-42f1-ae28-ac901f9a3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMSELECTOR.generate(query)\n",
    "LLMSELECTOR.load_history()['trace']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
