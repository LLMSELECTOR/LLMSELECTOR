{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6e40cc-4967-43a1-8e2f-f5e3aa912cac",
   "metadata": {},
   "source": [
    "## Config the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbcb1a46-4717-4f56-bca6-e682958da54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import llmselector, os\n",
    "if not os.path.exists('../cache/db_livecodebench.sqlite'): \n",
    "    !wget -P ../cache https://github.com/LLMSELECTOR/LLMSELECTOR/releases/download/0.0.1/db_livecodebench.sqlite\n",
    "llmselector.config.config(\n",
    "    db_path=f\"../cache/db_livecodebench.sqlite\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca36d16-bac3-46d1-ad26-8076d07ef7ec",
   "metadata": {},
   "source": [
    "## Load the livecodebench dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176500f3-9351-4345-9b21-568171635504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmselector.data_utils.livecodebench import DataLoader_livecodebench \n",
    "from sklearn.model_selection import train_test_split\n",
    "Mydataloader = DataLoader_livecodebench()\n",
    "q_data = Mydataloader.get_query_df()\n",
    "train_df, test_df = train_test_split(q_data,test_size=0.5, random_state=2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504d3b7f-a2f1-43ad-a31f-fb2c342fec45",
   "metadata": {},
   "source": [
    "## Use a single LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7981a1c1-2e87-4d9d-8ab6-296f42b99e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 963.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gpt-4o-2024-05-13', 'gpt-4o-2024-05-13', 'gpt-4o-2024-05-13')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 995.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20240620')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1318.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gemini-1.5-pro', 'gemini-1.5-pro', 'gemini-1.5-pro')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 2033.36it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 10008.38it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 1900.45it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 17657.44it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 2190.40it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 12998.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Name  Mean_Score\n",
      "0           gpt-4o-2024-05-13    0.862500\n",
      "1  claude-3-5-sonnet-20240620    0.891667\n",
      "2              gemini-1.5-pro    0.866667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from llmselector.compoundai.module.selfrefine import SelfRefine\n",
    "from llmselector.compoundai.optimizer import OptimizerFullSearch\n",
    "from llmselector.compoundai.metric import Metric, compute_score\n",
    "model_list = ['gpt-4o-2024-05-13','claude-3-5-sonnet-20240620','gemini-1.5-pro']\n",
    "Agents_SameModel ={}\n",
    "for name in model_list:\n",
    "    Agents_SameModel[name] = SelfRefine()\n",
    "    Opt0 = OptimizerFullSearch(model_list = [name])\n",
    "    Opt0.optimize( train_df, Metric('em'), Agents_SameModel[name])\n",
    "results = compute_score(Agents_SameModel, test_df, Metric('em'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1bf065-1199-4a43-9c9c-f3ad7897aff7",
   "metadata": {},
   "source": [
    "## Optimize model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8137c5b-510d-467b-aece-bce8bf6038d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-compute the score... with allocations: [['gpt-4o-2024-05-13', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-haiku-20240307'], ['gpt-4-turbo-2024-04-09', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-haiku-20240307'], ['gpt-4o-mini-2024-07-18', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-haiku-20240307'], ['claude-3-5-sonnet-20240620', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-haiku-20240307'], ['claude-3-haiku-20240307', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-haiku-20240307'], ['gemini-1.5-pro', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-haiku-20240307'], ['gemini-1.5-flash', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-haiku-20240307'], ['meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-haiku-20240307'], ['meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-haiku-20240307'], ['Qwen/Qwen2.5-72B-Instruct-Turbo', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-haiku-20240307']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1607.60it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1616.16it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1539.92it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1763.72it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1965.40it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1627.49it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1797.34it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1803.68it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1814.25it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1796.62it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 75.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-compute the score... with allocations: [['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'claude-3-haiku-20240307'], ['gemini-1.5-pro', 'gpt-4-turbo-2024-04-09', 'claude-3-haiku-20240307'], ['gemini-1.5-pro', 'gpt-4o-mini-2024-07-18', 'claude-3-haiku-20240307'], ['gemini-1.5-pro', 'claude-3-5-sonnet-20240620', 'claude-3-haiku-20240307'], ['gemini-1.5-pro', 'claude-3-haiku-20240307', 'claude-3-haiku-20240307'], ['gemini-1.5-pro', 'gemini-1.5-pro', 'claude-3-haiku-20240307'], ['gemini-1.5-pro', 'gemini-1.5-flash', 'claude-3-haiku-20240307'], ['gemini-1.5-pro', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-haiku-20240307'], ['gemini-1.5-pro', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'claude-3-haiku-20240307'], ['gemini-1.5-pro', 'Qwen/Qwen2.5-72B-Instruct-Turbo', 'claude-3-haiku-20240307']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1497.90it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1579.61it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1638.78it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1886.39it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1723.99it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1761.16it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1762.92it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1574.94it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1623.55it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1621.61it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.76it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 72.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-compute the score... with allocations: [['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'gpt-4o-2024-05-13'], ['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'gpt-4-turbo-2024-04-09'], ['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'gpt-4o-mini-2024-07-18'], ['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'claude-3-haiku-20240307'], ['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'gemini-1.5-pro'], ['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'gemini-1.5-flash'], ['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo'], ['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo'], ['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'Qwen/Qwen2.5-72B-Instruct-Turbo']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1805.79it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 888.74it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1885.78it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1600.13it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1768.20it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1947.67it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1836.72it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1738.55it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1612.15it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1641.65it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.52it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 74.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-compute the score... with allocations: [['gpt-4o-2024-05-13', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['gpt-4-turbo-2024-04-09', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['gpt-4o-mini-2024-07-18', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['claude-3-haiku-20240307', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['gemini-1.5-pro', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['gemini-1.5-flash', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['Qwen/Qwen2.5-72B-Instruct-Turbo', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1889.46it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1786.66it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 2082.60it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1921.19it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1834.14it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1892.77it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1642.40it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1596.46it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1577.28it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1554.65it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.07it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 73.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-compute the score... with allocations: [['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['claude-3-5-sonnet-20240620', 'gpt-4-turbo-2024-04-09', 'claude-3-5-sonnet-20240620'], ['claude-3-5-sonnet-20240620', 'gpt-4o-mini-2024-07-18', 'claude-3-5-sonnet-20240620'], ['claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20240620'], ['claude-3-5-sonnet-20240620', 'claude-3-haiku-20240307', 'claude-3-5-sonnet-20240620'], ['claude-3-5-sonnet-20240620', 'gemini-1.5-pro', 'claude-3-5-sonnet-20240620'], ['claude-3-5-sonnet-20240620', 'gemini-1.5-flash', 'claude-3-5-sonnet-20240620'], ['claude-3-5-sonnet-20240620', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'claude-3-5-sonnet-20240620'], ['claude-3-5-sonnet-20240620', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'claude-3-5-sonnet-20240620'], ['claude-3-5-sonnet-20240620', 'Qwen/Qwen2.5-72B-Instruct-Turbo', 'claude-3-5-sonnet-20240620']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1678.53it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1928.62it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1781.34it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 2149.13it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 2253.82it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1921.22it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1846.83it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1789.99it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1681.99it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1707.48it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.46it/s]\n",
      "100%|██████████| 239/239 [00:03<00:00, 77.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-compute the score... with allocations: [['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'gpt-4o-2024-05-13'], ['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'gpt-4-turbo-2024-04-09'], ['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'gpt-4o-mini-2024-07-18'], ['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'claude-3-5-sonnet-20240620'], ['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'claude-3-haiku-20240307'], ['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'gemini-1.5-pro'], ['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'gemini-1.5-flash'], ['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo'], ['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo'], ['claude-3-5-sonnet-20240620', 'gpt-4o-2024-05-13', 'Qwen/Qwen2.5-72B-Instruct-Turbo']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1701.06it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1718.56it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1712.89it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1688.54it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1641.67it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1578.96it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1643.09it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1650.37it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1827.39it/s]\n",
      "Processing: 100%|██████████| 239/239 [00:00<00:00, 1651.49it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.45it/s]\n",
      "100%|██████████| 239/239 [00:02<00:00, 80.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from llmselector.compoundai.optimizer import OptimizerLLMDiagnoser\n",
    "LLMSELECTOR = SelfRefine()\n",
    "Optimizer = OptimizerLLMDiagnoser()\n",
    "Optimizer.optimize( train_df, Metric('em'), LLMSELECTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ef77aa-ccda-4d66-9670-82d5570114ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 1750.47it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 17027.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name  Mean_Score\n",
      "0  LLMSELECTOR    0.954167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = compute_score({\"LLMSELECTOR\":LLMSELECTOR}, test_df, Metric('em'))\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMSELECTOR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19 (main, May  6 2024, 14:46:57) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a6d27e8a51c009f5716a7500b3d00c6679297ab34466bc881319ad79ecd6a0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
